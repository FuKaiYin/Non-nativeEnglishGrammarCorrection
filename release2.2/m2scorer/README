5 February 2013

This README file describes the NUS MaxMatch (M^2) scorer.
Copyright (C) 2012 Daniel Dahlmeier and Hwee Tou Ng

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.


If you are using the NUS M^2 scorer in your work, please include a
citation of the following paper:

Daniel Dahlmeier and Hwee Tou Ng. 2012. Better Evaluation for
Grammatical Error Correction. In Proceedings of the 2012 Conference of
the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies

Any questions regarding the NUS M^2 scorer should be directed to Daniel
Dahlmeier(danielhe@comp.nus.edu.sg).


Contents
========
0. Quickstart
1. Pre-requisites
2. Using the scorer
   2.1 System output format
   2.2 Scorer's gold standard format
3. Converting the CoNLL-2013 data format


0. Quickstart
=============
 ./m2scorer [-v] SYSTEM SOURCE_GOLD 

SYSTEM = the system output in sentence-per-line plain text.
SOURCE_GOLD = the source sentences with gold edits.


1. Pre-requisites
=================
The following dependencies have to be installed to use the M^2 scorer.

+ Python (>= 2.6.4, < 3.0, older versions might work but are not tested)
+ nltk (http://www.nltk.org, needed for sentence splitting) 



2. Using the scorer
===================
Usage: m2scorer [OPTIONS] SYSTEM SOURCE_GOLD
where
 SYSTEM          -   system output, one sentence per line
 SOURCE_GOLD     -   source sentences with gold token edits

OPTIONS
  -v    --verbose             -  print verbose output
  --very_verbose              -  print lots of verbose output
  --max_unchanged_words N     -  Maximum unchanged words when extracting edits. Default 2.
  --ignore_whitespace_casing  -  Ignore edits that only affect whitespace and casing. Default no.


2.1 System output format
========================
SYSTEM = File that contains the output of the error correction
system. The sentences should be in tokenized plain text, sentence-per-line
format.

Format:
<tokenized system output for sentence 1>
<tokenized system output for sentence 2>
 ...

Examples of tokenization:
-------------------------
 Original  : He said, "We shouldn't go to the place. It'll kill one of us."
 Tokenized : He said , " We shouldn 't go to the place . It 'll kill one of us . "

Sample output:
--------------
===> system <===
A cat sat on the mat .
The dog .


2.2 Scorer's gold standard format
=================================
SOURCE_GOLD = source sentences (i.e. input to the error correction
system) and the gold annotation in TOKEN offsets (starting from zero). 

Format:
S <tokenized system output for sentence 1>
A <token start offset> <token end offset>|||<error type>|||<correction1>||<correction2||..||correctionN|||<required>|||<comment>|||<annotator id>
A <token start offset> <token end offset>|||<error type>|||<correction1>||<correction2||..||correctionN|||<required>|||<comment>|||<annotator id>

S <tokenized system output for sentence 2>
A <token start offset> <token end offset>|||<error type>|||<correction1>||<correction2||..||correctionN|||<required>|||<comment>|||<annotator id>


Notes:
------
 - Each source sentence should appear on a single line starting with "S "
 - Each source sentence is followed by zero or more annotations.
 - Each annotation is on a separate line starting with "A ".
 - Sentences are separated by one or more empty lines.
 - The source sentences need to be tokenized in the same way as the system output.
 - Start and end offset for annotations are in token offsets (starting from zero).
 - The gold edits can include one or more  possible correction strings. Multiple corrections should be separate by '||'.
 - The error type, required field, comment and annotator id are not used for scoring at the moment. You can put dummy values there.


Example:
--------
===> source_gold <===
S The cat sat at mat .
A 3 4|||RT|||on|||REQUIRED|||-NONE-|||0
A 4 4|||MD|||the||a|||REQUIRED|||-NONE-|||0

S The dog .
A 1 2|||FN|||dogs|||REQUIRED|||-NONE-|||0

===> system <===
A cat sat on the mat .
The dog .

./m2scorer  system source_gold 
Precision   : 0.6667
Recall      : 0.6667
F1          : 0.6667

The system makes two valid edits {(at-> on), (\epsilon -> the)}, one
unnecessary edit (The -> A), and misses one gold edit (dog -> dogs).
Precision is 2/3 = 0.6667. Similarly for recall and F1 measure.



3. Converting the NUCLE data format
===================================

The data format used in the M^2 scorer differs from the format used in
the sgml data set for CoNLL-2013 shared task (token offsets
vs. character offsets).

To convert source texts and gold edits from the CoNLL-2013 sgml data
format into the M^2 format, run the preprocessing script bundled with
the CoNLL-2013 training data with the following commands (from the
training data directory):

./preprocess.py -l RAW_DATA CONLL_COLUMN CONLL_ANNOTATION M2_SOURCE_GOLD

with the following description:

RAW_DATA          = file name of the sgml data format used in the CoNLL-2013 shared task
CONLL_COLUMN      = file name of the by-product of the preprocessing step, i.e. pre-processed
                    data in CoNLL standard column format
CONLL_ANNOTATION  = file name of another by-product of the preprocessing step, i.e. token-level
                    annotation
M2_SOURCE_GOLD    = file name of the source texts and gold annotations in M^2 format, for evaluation
